{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDA project: predicting crowdedness in Leuven through noise and weather data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and adding time-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"...\", delimiter=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines to fit all models (with cross-validation and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'DateOffset' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8772\\1067384093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#Apply to df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelay_noise_weather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8772\\1067384093.py\u001b[0m in \u001b[0;36mdelay_noise_weather\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Add 6 hours to result_timestamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf_noisedelay\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result_timestamp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Create key column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__iadd__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m  11370\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11371\u001b[0m         \u001b[1;31m# error: Unsupported left operand type for + (\"Type[NDFrame]\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11372\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inplace_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__add__\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[operator]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__isub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_inplace_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m  11347\u001b[0m         \u001b[0mWrap\u001b[0m \u001b[0marithmetic\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mto\u001b[0m \u001b[0moperate\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11348\u001b[0m         \"\"\"\n\u001b[1;32m> 11349\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11351\u001b[0m         if (\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__add__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__radd__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_method_SERIES\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;31m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# because numexpr will fail on it, see GH#31457\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;31m# TODO we should handle EAs consistently and move this check before the if/else\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.BaseOffset.__add__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\saaan\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.BaseOffset.__add__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'DateOffset' and 'str'"
     ]
    }
   ],
   "source": [
    "#pipeline to create feature matrix with delayed noise and weather data, as well as target vector.\n",
    "\n",
    "def delay_noise_weather(df):\n",
    "    # Select columns for df_noisedelay\n",
    "    df_noisedelay = df[['object_id', 'result_timestamp', 'laeq']]\n",
    "\n",
    "    # Add 6 hours to result_timestamp\n",
    "    df_noisedelay['result_timestamp'] += pd.DateOffset(hours=6)\n",
    "\n",
    "    # Create key column\n",
    "    df_noisedelay['key'] = df_noisedelay['object_id'].astype(str) + df_noisedelay['result_timestamp'].astype(str)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_noisedelay = df_noisedelay.drop(['laeq', 'object_id', 'result_timestamp'], axis=1)\n",
    "\n",
    "    # Select columns for df_weatherdelay\n",
    "    df_weatherdelay = df[['object_id', 'result_timestamp', 'LC_HUMIDITY', 'LC_DWPTEMP', 'LC_n', 'LC_RAD', 'LC_RAININ',\n",
    "                          'LC_DAILYRAIN', 'LC_WINDDIR', 'LC_WINDSPEED', 'LC_RAD60', 'LC_TEMP_QCL0']]\n",
    "\n",
    "    # Add 6 hours to result_timestamp\n",
    "    df_weatherdelay['result_timestamp'] += pd.DateOffset(hours=6)\n",
    "\n",
    "    # Create key column\n",
    "    df_weatherdelay['key'] = df_weatherdelay['object_id'].astype(str) + df_weatherdelay['result_timestamp'].astype(str)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_weatherdelay = df_weatherdelay.drop(['object_id', 'result_timestamp'], axis=1)\n",
    "\n",
    "    # Drop weather-related columns from original df\n",
    "    df = df.drop(['LC_HUMIDITY', 'LC_DWPTEMP', 'LC_n', 'LC_RAD', 'LC_RAININ',\n",
    "                  'LC_DAILYRAIN', 'LC_WINDDIR', 'LC_WINDSPEED', 'LC_RAD60', 'LC_TEMP_QCL0'], axis=1)\n",
    "\n",
    "    # Merge df with df_noisedelay and df_weatherdelay on 'key'\n",
    "    merged_df = pd.merge(df, df_noisedelay, on='key').merge(df_weatherdelay, on='key')\n",
    "\n",
    "    # Delete observations with missing values\n",
    "    merged_df = merged_df.dropna()\n",
    "\n",
    "    # Create feature matrix X and target vector y\n",
    "    X = merged_df.drop(['result_timestamp', 'laeq'], axis=1)\n",
    "    y = merged_df['laeq']\n",
    "\n",
    "    # Return feature matrix X and target vector y\n",
    "    return X, y\n",
    "\n",
    "#Apply to df\n",
    "X, y = delay_noise_weather(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time-sensitive split for cross-validation\n",
    "ts_cv = TimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    gap=12960,\n",
    "    max_train_size=26300,\n",
    "    test_size=18347,\n",
    ")\n",
    "\n",
    "#apply split to the data\n",
    "all_splits = list(ts_cv.split(X, y))\n",
    "\n",
    "#visualize train and test sets\n",
    "#...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline to run the three models, perform hyperparameter tuning and select the best performing model\n",
    "\n",
    "def evaluate_models(X, y, cv, models):\n",
    "    best_model = None\n",
    "    best_score = float('-inf')\n",
    "\n",
    "    for model in models:\n",
    "        if isinstance(model, XGBRegressor):\n",
    "            # Parameter grid for XGBoost model\n",
    "            param_grid = {\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [3, 4, 5]\n",
    "            }\n",
    "        elif isinstance(model, HistGradientBoostingRegressor):\n",
    "            # Parameter grid for HistGradientBoostingRegressor model\n",
    "            param_grid = {\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'max_iter': [100, 200, 300],\n",
    "                'max_depth': [3, 4, 5]\n",
    "            }\n",
    "        else:\n",
    "            # Use default hyperparameters for other models\n",
    "            best_model = model\n",
    "            print(f\"Using default hyperparameters for model: {type(model).__name__}\")\n",
    "            continue\n",
    "\n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(model, param_grid=param_grid, cv=cv)\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        # Get the best parameters and score from the search\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        print(f\"Results of Grid Search for model: {type(model).__name__}\")\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"Best Score: {best_score}\")\n",
    "\n",
    "        if best_score > best_model_score:\n",
    "            best_model = model.set_params(**best_params)\n",
    "\n",
    "    if best_model is not None:\n",
    "        # Train the best model with the entire dataset\n",
    "        best_model.fit(X, y)\n",
    "        y_pred = best_model.predict(X)\n",
    "\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "\n",
    "        print(f\"Best Model: {type(best_model).__name__}\")\n",
    "        print(f\"Mean Absolute Error:     {mae:.3f}\")\n",
    "        print(f\"Root Mean Squared Error: {rmse:.3f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# Define the models to evaluate\n",
    "models = [XGBRegressor(), HistGradientBoostingRegressor(), other_model()]\n",
    "\n",
    "# Example usage with multiple models\n",
    "best_model = evaluate_models(X, y, cv, models)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of results of final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapley values\n",
    "# # replace i with index of last fold (i think tis is 4)\n",
    "X_train=X.iloc[all_splits[2][0]]\n",
    "X_test=X.iloc[all_splits[2][1]]\n",
    "y_train=y.iloc[all_splits[2][0]]\n",
    "y_test=y.iloc[all_splits[2][1]]\n",
    "#use selected model\n",
    "model=best_model\n",
    "fit = model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "#summary plot\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "#bar chart\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "#explain a single prediction: see https://www.kaggle.com/code/dansbecker/shap-values\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:])\n",
    "# explain more predictions: don't really know how this works\n",
    "shap.force_plot(explainer.expected_value, shap_values[:500,:], X_test.iloc[:500,:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_mda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
