{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from dask.distributed import Client\n",
    "import seaborn as sns\n",
    "import coiled\n",
    "import dask\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43643</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>36</li>\n",
       "  <li><b>Memory: </b>21.47 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:43643' processes=4 threads=36, memory=21.47 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a local Dask cluster and connect it to the client. This is useful to follow the computation memory usage and execution time.  \n",
    "#Requires Dask JupyterLab extension to follow the Dashboard. For more information, please look at: https://docs.dask.org/en/stable/dashboard.html\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the working directory. \n",
    "os.chdir(\"/data/leuven/351/vsc35102/scratch/Full_Data_Set/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the data from an online location\n",
    "#gdown.download_folder(\"https://drive.google.com/drive/folders/1HT-ctj8Aj6qcVMZYBxi3YM4XC9fbFjSN?usp=share_link\", quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function to covert the .csv files into .parquet files, optimized for a fast runtime.\n",
    "\n",
    "class CSVtoParquetConverter:\n",
    "    def __init__(self, base_folder):\n",
    "        self.base_folder = base_folder\n",
    "\n",
    "    def convert_csv_to_parquet(self):\n",
    "        months = ['Jan', 'Feb', 'March', 'April', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        for month in months:\n",
    "            folder_path = os.path.join(self.base_folder, month)\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "            for csv_file in csv_files:\n",
    "                csv_path = os.path.join(folder_path, csv_file)\n",
    "                df = dd.read_csv(csv_path, sep=\";\")\n",
    "\n",
    "                parquet_file = os.path.splitext(csv_file)[0] + '_parquet'\n",
    "                parquet_path = os.path.join(folder_path, parquet_file)\n",
    "\n",
    "                df.to_parquet(parquet_path, engine='pyarrow', compression=\"snappy\")\n",
    "                print(f\"Converted {csv_file} to {parquet_file}\")\n",
    "\n",
    "base_folder = '/data/leuven/351/vsc35102/scratch/Full_Data_Set/'\n",
    "converter = CSVtoParquetConverter(base_folder)\n",
    "converter.convert_csv_to_parquet()\n",
    "\n",
    "\n",
    "# Runtime: 2m 6.8 sec for all files on average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process .parquet files into Dask dataframe, subsample data into 10min intervals and return pandas dataframe. \n",
    "#Note that this chunk was not optimized in oop fashion to boost the performance.\n",
    "\n",
    "\n",
    "def process_data_by_month():\n",
    "    os.chdir(\"/data/leuven/351/vsc35102/scratch/Full_Data_Set/\")\n",
    "\n",
    "    months = ['Jan', 'Feb', 'March', 'April', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    base_folder = '/data/leuven/351/vsc35102/scratch/Full_Data_Set/'\n",
    "    output_folder = '/data/leuven/351/vsc35102/scratch/Full_Data_Set/output/'\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create output folder (in case it done not yet exisit).\n",
    "\n",
    "    dfs = []  # List to store the individual Pandas dataframes. \n",
    "\n",
    "    for month in months:\n",
    "        flat_list = glob.glob(os.path.join(base_folder, month, '*_parquet/*.parquet'))\n",
    "        ddf = dd.read_parquet(flat_list, columns=[\"#object_id\", \"description\", \"result_timestamp\", \"laeq\"]) #Read only columns that are going to be used in the model.\n",
    "\n",
    "        # Convert to the desired data types to boost the performance. Note that object type are very computationaly expensive and it is recommended to specify the corresponding datatype for each column.\n",
    "        ddf = ddf.astype({'description': 'string', 'laeq': 'float'})\n",
    "\n",
    "        # Set the timestamp into the correct form and set the index to result_timestamp. Note that this is a bottleneck step.\n",
    "        ddf[\"result_timestamp\"] = dd.to_datetime(ddf[\"result_timestamp\"], dayfirst=True, format=\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "        ddf_sorted = ddf.set_index('result_timestamp')\n",
    "\n",
    "        pandas_df = ddf_sorted.compute().reset_index()  # Convert to Pandas DataFrame.\n",
    "\n",
    "        pandas3 = pandas_df.groupby(\"description\").resample(\"10T\", on=\"result_timestamp\").agg({'laeq': 'mean'}).reset_index()\n",
    "\n",
    "        dfs.append(pandas3)\n",
    "\n",
    "    combined_df = pd.concat(dfs)  # Combine all individual  dataframes into a single dataframe.\n",
    "    return combined_df\n",
    "\n",
    "# Runtime: 9min 3sec for all files on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to process the data for each month\n",
    "table = process_data_by_month()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>laeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP 03: Naamsestraat 62 Taste</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>63.267554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP 03: Naamsestraat 62 Taste</td>\n",
       "      <td>2022-01-01 00:10:00</td>\n",
       "      <td>60.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP 03: Naamsestraat 62 Taste</td>\n",
       "      <td>2022-01-01 00:20:00</td>\n",
       "      <td>55.143907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP 03: Naamsestraat 62 Taste</td>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>58.230167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP 03: Naamsestraat 62 Taste</td>\n",
       "      <td>2022-01-01 00:40:00</td>\n",
       "      <td>54.220466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    description    result_timestamp       laeq\n",
       "0  MP 03: Naamsestraat 62 Taste 2022-01-01 00:00:00  63.267554\n",
       "1  MP 03: Naamsestraat 62 Taste 2022-01-01 00:10:00  60.254000\n",
       "2  MP 03: Naamsestraat 62 Taste 2022-01-01 00:20:00  55.143907\n",
       "3  MP 03: Naamsestraat 62 Taste 2022-01-01 00:30:00  58.230167\n",
       "4  MP 03: Naamsestraat 62 Taste 2022-01-01 00:40:00  54.220466"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the table.\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFeatureGenerator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_time_features(self, df):\n",
    "        df['date'] = df['result_timestamp'].dt.date\n",
    "        df['time'] = df['result_timestamp'].dt.time\n",
    "        df['hour'] = df['result_timestamp'].dt.hour\n",
    "        df['weekday'] = df['result_timestamp'].dt.day_name()\n",
    "        df['month'] = df['result_timestamp'].dt.month\n",
    "        df['weekend'] = df['weekday'].isin(['Saturday', 'Sunday'])\n",
    "        return df\n",
    "\n",
    "time_feature_generator = TimeFeatureGenerator()\n",
    "time_features = time_feature_generator.add_time_features(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define holidays that may impact the noise levels\n",
    "\n",
    "class HolidayDetector:\n",
    "    def __init__(self):\n",
    "        self.holidays = self.generate_holidays()\n",
    "\n",
    "    def generate_holidays(self):\n",
    "        holiday_ranges = []\n",
    "        holiday_dates = [\n",
    "            ('2022-01-01', '2022-01-13'),\n",
    "            ('2022-02-02', '2022-02-02'),\n",
    "            ('2022-02-06', '2022-02-13'),\n",
    "            ('2022-04-02', '2022-04-18'),\n",
    "            ('2022-05-01', '2022-05-01'),\n",
    "            ('2022-05-26', '2022-05-26'),\n",
    "            ('2022-05-28', '2022-06-12'),\n",
    "            ('2022-07-03', '2022-09-25'),\n",
    "            ('2022-11-01', '2022-11-02'),\n",
    "            ('2022-11-11', '2022-11-11'),\n",
    "            ('2022-12-24', '2022-12-31')\n",
    "        ]\n",
    "        for start_date, end_date in holiday_dates:\n",
    "            holiday_ranges.append(pd.date_range(start=start_date, end=end_date))\n",
    "        holidays = pd.concat([pd.DataFrame(date_range) for date_range in holiday_ranges], ignore_index=True)\n",
    "        holidays.columns = ['dates']\n",
    "        return holidays\n",
    "\n",
    "    def detect_holidays(self, time_features):\n",
    "        time_features['holiday'] = time_features['date'].astype(str).isin(self.holidays['dates'].astype(str))\n",
    "        return time_features\n",
    "    \n",
    "holiday_detector = HolidayDetector()\n",
    "time_features = holiday_detector.detect_holidays(time_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ExamPeriodDetector:\n",
    "    def __init__(self):\n",
    "        self.exam_periods = self.generate_exam_periods()\n",
    "\n",
    "    def generate_exam_periods(self):\n",
    "        exam_ranges = [\n",
    "            ('2022-01-14', '2022-02-05'),\n",
    "            ('2022-06-13', '2022-07-02'),\n",
    "            ('2022-08-22', '2022-09-10')\n",
    "        ]\n",
    "        exam_periods = pd.concat([pd.DataFrame(pd.date_range(start, end)) for start, end in exam_ranges], ignore_index=True)\n",
    "        exam_periods.columns = ['dates']\n",
    "        return exam_periods\n",
    "\n",
    "    def detect_exam_periods(self, time_features):\n",
    "        time_features['exam_period'] = time_features['date'].astype(str).isin(self.exam_periods['dates'].astype(str))\n",
    "        return time_features\n",
    "\n",
    "\n",
    "exam_period_detector = ExamPeriodDetector()\n",
    "time_features = exam_period_detector.detect_exam_periods(time_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Already tz-aware, use tz_convert to convert.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e52cd4bc2b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Localize the datetime object to the Belgian timezone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This keeps in mind the change from CET to CEST in spring and CEST to CET in autumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtime_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CET'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mambiguous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NaT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnonexistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NaT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_create_delegator_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delegate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m_delegate_method\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mtz_localize\u001b[0;34m(self, tz, ambiguous, nonexistent)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonexistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     ) -> \"DatetimeIndex\":\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonexistent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mtz_localize\u001b[0;34m(self, tz, ambiguous, nonexistent)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mnew_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtzconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_convert_from_utc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masi8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Already tz-aware, use tz_convert to convert.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimezones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_get_tz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Already tz-aware, use tz_convert to convert."
     ]
    }
   ],
   "source": [
    "# Localize the datetime object to the Belgian timezone\n",
    "# This keeps in mind the change from CET to CEST in spring and CEST to CET in autumn\n",
    "time_features['result_timestamp'] = pd.to_datetime(time_features['result_timestamp']).dt.tz_localize('CET',ambiguous='NaT',nonexistent='NaT')\n",
    "\n",
    "time_features = time_features.dropna(subset=['result_timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save it to .csv file\n",
    "time_features.to_csv('/data/leuven/351/vsc35102/scratch/Full_Data_Set/time_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the weather data \n",
    "\n",
    "def read_multiple_csv(folder_path, columns_to_select):\n",
    "    dfs = []  # List to store individual DataFrames\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df = pd.read_csv(file_path, usecols=columns_to_select, parse_dates=['DATEUTC'])\n",
    "            dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "folder_path = '/data/leuven/351/vsc35102/scratch/Full_Data_Set/weather'\n",
    "columns_to_select = ['ID','DATEUTC', 'LC_HUMIDITY', 'LC_DWPTEMP', 'LC_n', 'LC_RAD', 'LC_RAININ', 'LC_DAILYRAIN', 'LC_WINDDIR', 'LC_WINDSPEED', 'LC_RAD60', 'LC_TEMP_QCL0', 'LC_TEMP_QCL1', 'LC_TEMP_QCL2', 'LC_TEMP_QCL3']\n",
    "\n",
    "weather = read_multiple_csv(folder_path, columns_to_select)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEUTC</th>\n",
       "      <th>ID</th>\n",
       "      <th>LC_HUMIDITY</th>\n",
       "      <th>LC_DWPTEMP</th>\n",
       "      <th>LC_n</th>\n",
       "      <th>LC_RAD</th>\n",
       "      <th>LC_RAININ</th>\n",
       "      <th>LC_DAILYRAIN</th>\n",
       "      <th>LC_WINDDIR</th>\n",
       "      <th>LC_WINDSPEED</th>\n",
       "      <th>LC_RAD60</th>\n",
       "      <th>LC_TEMP_QCL0</th>\n",
       "      <th>LC_TEMP_QCL1</th>\n",
       "      <th>LC_TEMP_QCL2</th>\n",
       "      <th>LC_TEMP_QCL3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:10:00</td>\n",
       "      <td>LC-002</td>\n",
       "      <td>92.0</td>\n",
       "      <td>11.78</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.0515</td>\n",
       "      <td>13.048027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 00:20:00</td>\n",
       "      <td>LC-002</td>\n",
       "      <td>92.0</td>\n",
       "      <td>11.73</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.01</td>\n",
       "      <td>13.01</td>\n",
       "      <td>12.9515</td>\n",
       "      <td>12.985849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>LC-002</td>\n",
       "      <td>92.0</td>\n",
       "      <td>11.73</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.9415</td>\n",
       "      <td>12.950322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 00:40:00</td>\n",
       "      <td>LC-002</td>\n",
       "      <td>92.0</td>\n",
       "      <td>11.72</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.9415</td>\n",
       "      <td>12.949550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 00:50:00</td>\n",
       "      <td>LC-002</td>\n",
       "      <td>92.0</td>\n",
       "      <td>11.72</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.9415</td>\n",
       "      <td>12.952268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATEUTC      ID  LC_HUMIDITY  LC_DWPTEMP  LC_n  LC_RAD  \\\n",
       "0 2022-01-01 00:10:00  LC-002         92.0       11.78  38.0     0.0   \n",
       "1 2022-01-01 00:20:00  LC-002         92.0       11.73  37.0     0.0   \n",
       "2 2022-01-01 00:30:00  LC-002         92.0       11.73  38.0     0.0   \n",
       "3 2022-01-01 00:40:00  LC-002         92.0       11.72  37.0     0.0   \n",
       "4 2022-01-01 00:50:00  LC-002         92.0       11.72  38.0     0.0   \n",
       "\n",
       "   LC_RAININ  LC_DAILYRAIN  LC_WINDDIR  LC_WINDSPEED  LC_RAD60  LC_TEMP_QCL0  \\\n",
       "0        0.0           0.0      -169.0          0.43       0.0         13.11   \n",
       "1        0.0           0.0      -170.0          0.33       0.0         13.01   \n",
       "2        0.0           0.0      -167.0          0.46       0.0         13.00   \n",
       "3        0.0           0.0      -160.0          0.52       0.0         13.00   \n",
       "4        0.0           0.0      -166.0          0.51       0.0         13.00   \n",
       "\n",
       "   LC_TEMP_QCL1  LC_TEMP_QCL2  LC_TEMP_QCL3  \n",
       "0         13.11       13.0515     13.048027  \n",
       "1         13.01       12.9515     12.985849  \n",
       "2         13.00       12.9415     12.950322  \n",
       "3         13.00       12.9415     12.949550  \n",
       "4         13.00       12.9415     12.952268  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant location.\n",
    "weather105_location = weather[weather['ID'] == 'LC-105']\n",
    "\n",
    "# Modify the timestamp. \n",
    "weather105_location.rename(columns={'DATEUTC':'result_timestamp'},inplace=True)\n",
    "weather105_location['result_timestamp'] = pd.to_datetime(weather105_location['result_timestamp'],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#Add the UTC timezone information to the result_timestamp\n",
    "weather105_location['result_timestamp'] = pd.to_datetime(weather105_location['result_timestamp']).dt.tz_localize('UTC')\n",
    "\n",
    "#Change weather data to CET timezone\n",
    "weather105_location['result_timestamp'] = pd.to_datetime(weather105_location['result_timestamp']).dt.tz_convert('CET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge noise and weather data.\n",
    "full_dataframe = pd.merge(time_features, weather105_location, on='result_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with only weather data, but no noise data.\n",
    "full_dataframe = full_dataframe[full_dataframe.isnull()['laeq']==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data \n",
    "full_dataframe.to_csv('/data/leuven/351/vsc35102/scratch/Full_Data_Set/Project_dataframe.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
